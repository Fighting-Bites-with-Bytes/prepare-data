
## Prepare Ticks data

```{r}
#| message: false
#| warning: false

library("dplyr")
library("sf")
library("readr")
library("ggplot2")
library("plotly")
library("purrr")
library("janitor")
library("lubridate")

options("sf_max.plot" = 1)

tick_reports <- read_csv("data-raw/classified/tick-reports.csv")
swissboundaries_path <- "data-raw/public/swissTLM/swissBOUNDARIES3D_1_4_LV95_LN02.gdb"
# st_layers(swissboundaries_path)

switzerland <- read_sf(swissboundaries_path, "TLM_LANDESGEBIET") |>
  st_zm() |>
  filter(NAME != "Liechtenstein") |>
  st_union() |>
  st_transform(2056)

# clean column names and format columns
tick_reports <- tick_reports |>
  janitor::clean_names() |>
  mutate(across(c(id, x, y, acc, body_part, report_type, age, gender, host, pickup, deleted), ~ as.integer(.x))) |>
  mutate(across(c(lat, lon, date_acc), ~ as.numeric(.x))) |>
  mutate(
    datetime = as.POSIXct(date, format = "%Y-%m-%d %H:%M:%S"),
    date = as.Date(datetime)
  )

# remove rows without a data or data is older than 2015
tick_reports <- tick_reports |>
  filter(!is.na(date)) |>
  filter(date > "2015-01-01")



# remove reports outside a oversized bounding box
# This is redundant, as the data will be filtered by swissBOUNDARIES3D later
XMIN_21781 <- 485000
XMAX_21781 <- 834000
YMAX_21781 <- 296000
YMIN_21781 <- 075000

tick_reports <- tick_reports %>%
  filter(x < XMAX_21781, x > XMIN_21781) %>%
  filter(y < YMAX_21781, y > YMIN_21781)

# remove reports without a uuid or reports that are marked as deleted
tick_reports <- tick_reports %>%
  filter(uuid != "") %>%
  filter(deleted != 1)


# till now, all steps are relatively straightforward. Now, opinions start to
# matter.


# remove reports with a spatial accuracy of more than 1 km radius
tick_reports <- tick_reports |>
  filter(acc < 1000)

# this step is not necessary anymore, I'll keep it here to document
# default acc values. There are more default values it seems, as can be seen
# when visualizing the data as a histogram
tick_reports <- tick_reports %>%
  filter(!(acc %in% c(57274L, 64434L, 1014L)))

tick_reports_sf <- st_as_sf(tick_reports, coords = c("lon", "lat"), crs = 4326)

# I dont know who came up with this, but it doesn't seem to be the case that there
# are more locations near the default locations than outside
default_locations <- data.frame(lat = c(47.3647, 46.81), lon = c(8.5534, 8.23)) |>
  st_as_sf(coords = c("lon", "lat"), crs = 4326)

is_default <- st_is_within_distance(tick_reports_sf, default_locations, 1000) |>
  map_lgl(\(x)length(x) > 0)

sum(is_default)


# date accuracy only has two values: 43'200 and 432'000 (0.5 and 5 days?)
# There are only 8k reports for the higher value, we can discard these
table(tick_reports$date_acc)

tick_reports <- tick_reports |>
  filter(date_acc < 50000)


tick_reports$date_acc <- NULL
tick_reports$body_part <- NULL
tick_reports$report_type <- NULL
tick_reports$age <- NULL
tick_reports$gender <- NULL
tick_reports$host <- NULL
tick_reports$pickup <- NULL
tick_reports$uuid <- NULL
tick_reports$comment <- NULL
tick_reports$deleted <- NULL


# some reports are obivously duplicates: same x and y and date (time may vary slighly)
tick_reports |>
  group_by(x, y, date) |>
  filter(n() > 1) |>
  select(id, datetime)

# keep only distinct reports
tick_reports <- tick_reports |>
  distinct(x, y, date, .keep_all = TRUE)


tick_reports$x <- NULL
tick_reports$y <- NULL

tick_reports_sf <- st_as_sf(tick_reports, coords = c("lon", "lat"), crs = 4326) |>
  st_transform(2056)


tick_reports_sf <- cbind(tick_reports_sf, st_coordinates(tick_reports_sf))

tick_reports_sf <- tick_reports_sf[switzerland, , ]


tick_reports_sf$year <- year(tick_reports_sf$date)

ggplot(tick_reports_sf) +
  geom_sf() +
  facet_wrap(~year)


tick_reports_sf$year <- NULL

ticks_path <- "data-processed/Ticks"

if(!dir.exists(ticks_path)) {dir.create(ticks_path)}

st_write(tick_reports_sf, file.path(ticks_path, "tick_reports.gpkg"), "reports_0.2")

```