
## Prepare Ticks data {#test}

The tick data is user generated with the TickApp, see @sec-abstract \nameref{test}.

```{r}
#| message: false
#| warning: false

library("dplyr")
library("sf")
library("readr")
library("ggplot2")
library("plotly")
library("purrr")
library("janitor")
library("lubridate")

options("sf_max.plot" = 1)

```

```{r}


tick_reports <- read_csv("../data-raw/classified/tick_reports.csv")
swissboundaries_path <- "../data-raw/public/swissTLM/swissBOUNDARIES3D_1_4_LV95_LN02.gdb"
# st_layers(swissboundaries_path)

switzerland <- read_sf(swissboundaries_path, "TLM_LANDESGEBIET") |>
  st_zm() |>
  filter(NAME != "Liechtenstein") |>
  st_union() |>
  st_transform(2056)

# clean column names and format columns
tick_reports <- tick_reports |>
  janitor::clean_names() |>
  mutate(across(c(id, x, y, acc), ~ as.integer(.x))) |>
  mutate(across(c(lat, lon, date_acc), ~ as.numeric(.x))) |>
  mutate(
    datetime = as.POSIXct(date, format = "%Y-%m-%d %H:%M:%S"),
    date = as.Date(datetime)
  )




```

```{r}

```

```{r}

# remove reports with a spatial accuracy of more than 1 km radius
tick_reports <- tick_reports |>
  filter(acc < 1000)

# this step is not necessary anymore, I'll keep it here to document
# default acc values. There are more default values it seems, as can be seen
# when visualizing the data as a histogram
tick_reports <- tick_reports %>%
  filter(!(acc %in% c(57274L, 64434L, 1014L)))

tick_reports_sf <- st_as_sf(tick_reports, coords = c("lon", "lat"), crs = 4326)

# I dont know who came up with this, but it doesn't seem to be the case that there
# are more locations near the default locations than outside
default_locations <- data.frame(lat = c(47.3647, 46.81), lon = c(8.5534, 8.23)) |>
  st_as_sf(coords = c("lon", "lat"), crs = 4326)

is_default <- st_is_within_distance(tick_reports_sf, default_locations, 1000) |>
  map_lgl(\(x)length(x) > 0)

sum(is_default)


# date accuracy only has two values: 43'200 and 432'000 (0.5 and 5 days?)
# There are only 8k reports for the higher value, we can discard these
table(tick_reports$date_acc)

tick_reports <- tick_reports |>
  filter(date_acc < 50000)

```



```{r}

# some reports are obivously duplicates: same x and y and date (time may vary slighly)
tick_reports |>
  group_by(x, y, date) |>
  filter(n() > 1) |>
  select(id, datetime)

# keep only distinct reports
tick_reports <- tick_reports |>
  distinct(x, y, date, .keep_all = TRUE)


tick_reports$x <- NULL
tick_reports$y <- NULL

tick_reports_sf <- st_as_sf(tick_reports, coords = c("lon", "lat"), crs = 4326) |>
  st_transform(2056)


tick_reports_sf <- cbind(tick_reports_sf, st_coordinates(tick_reports_sf))

tick_reports_sf <- tick_reports_sf[switzerland, , ]


tick_reports_sf$year <- year(tick_reports_sf$date)

ggplot(tick_reports_sf) +
  geom_sf() +
  facet_wrap(~year)

```

```{r}
tick_reports_sf$year <- NULL

ticks_path <- "../data-processed/Ticks"

if(!dir.exists(ticks_path)) {dir.create(ticks_path)}

st_write(tick_reports_sf, file.path(ticks_path, "tick_reports.gpkg"), "reports_0.1", append = FALSE)

```