[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Preface",
    "section": "",
    "text": "Preface\nDocumenting data preperation steps"
  },
  {
    "objectID": "01_Clean_reports.html",
    "href": "01_Clean_reports.html",
    "title": "1  Prepare Ticks data",
    "section": "",
    "text": "library(\"dplyr\")\nlibrary(\"sf\")\nlibrary(\"readr\")\nlibrary(\"ggplot2\")\nlibrary(\"plotly\")\nlibrary(\"purrr\")\nlibrary(\"janitor\")\nlibrary(\"lubridate\")\n\noptions(\"sf_max.plot\" = 1)\n\ntick_reports &lt;- read_csv(\"data-raw/classified/tick-reports.csv\")\nswissboundaries_path &lt;- \"data-raw/public/swissTLM/swissBOUNDARIES3D_1_4_LV95_LN02.gdb\"\n# st_layers(swissboundaries_path)\n\nswitzerland &lt;- read_sf(swissboundaries_path, \"TLM_LANDESGEBIET\") |&gt;\n  st_zm() |&gt;\n  filter(NAME != \"Liechtenstein\") |&gt;\n  st_union() |&gt;\n  st_transform(2056)\n\n# clean column names and format columns\ntick_reports &lt;- tick_reports |&gt;\n  janitor::clean_names() |&gt;\n  mutate(across(c(id, x, y, acc, body_part, report_type, age, gender, host, pickup, deleted), ~ as.integer(.x))) |&gt;\n  mutate(across(c(lat, lon, date_acc), ~ as.numeric(.x))) |&gt;\n  mutate(\n    datetime = as.POSIXct(date, format = \"%Y-%m-%d %H:%M:%S\"),\n    date = as.Date(datetime)\n  )\n\n# remove rows without a data or data is older than 2015\ntick_reports &lt;- tick_reports |&gt;\n  filter(!is.na(date)) |&gt;\n  filter(date &gt; \"2015-01-01\")\n\n\n\n# remove reports outside a oversized bounding box\n# This is redundant, as the data will be filtered by swissBOUNDARIES3D later\nXMIN_21781 &lt;- 485000\nXMAX_21781 &lt;- 834000\nYMAX_21781 &lt;- 296000\nYMIN_21781 &lt;- 075000\n\ntick_reports &lt;- tick_reports %&gt;%\n  filter(x &lt; XMAX_21781, x &gt; XMIN_21781) %&gt;%\n  filter(y &lt; YMAX_21781, y &gt; YMIN_21781)\n\n# remove reports without a uuid or reports that are marked as deleted\ntick_reports &lt;- tick_reports %&gt;%\n  filter(uuid != \"\") %&gt;%\n  filter(deleted != 1)\n\n\n# till now, all steps are relatively straightforward. Now, opinions start to\n# matter.\n\n\n# remove reports with a spatial accuracy of more than 1 km radius\ntick_reports &lt;- tick_reports |&gt;\n  filter(acc &lt; 1000)\n\n# this step is not necessary anymore, I'll keep it here to document\n# default acc values. There are more default values it seems, as can be seen\n# when visualizing the data as a histogram\ntick_reports &lt;- tick_reports %&gt;%\n  filter(!(acc %in% c(57274L, 64434L, 1014L)))\n\ntick_reports_sf &lt;- st_as_sf(tick_reports, coords = c(\"lon\", \"lat\"), crs = 4326)\n\n# I dont know who came up with this, but it doesn't seem to be the case that there\n# are more locations near the default locations than outside\ndefault_locations &lt;- data.frame(lat = c(47.3647, 46.81), lon = c(8.5534, 8.23)) |&gt;\n  st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\n\nis_default &lt;- st_is_within_distance(tick_reports_sf, default_locations, 1000) |&gt;\n  map_lgl(\\(x)length(x) &gt; 0)\n\nsum(is_default)\n\n[1] 23\n\n# date accuracy only has two values: 43'200 and 432'000 (0.5 and 5 days?)\n# There are only 8k reports for the higher value, we can discard these\ntable(tick_reports$date_acc)\n\n\n 43200 432000 \n 39959   8253 \n\ntick_reports &lt;- tick_reports |&gt;\n  filter(date_acc &lt; 50000)\n\n\ntick_reports$date_acc &lt;- NULL\ntick_reports$body_part &lt;- NULL\ntick_reports$report_type &lt;- NULL\ntick_reports$age &lt;- NULL\ntick_reports$gender &lt;- NULL\ntick_reports$host &lt;- NULL\ntick_reports$pickup &lt;- NULL\ntick_reports$uuid &lt;- NULL\ntick_reports$comment &lt;- NULL\ntick_reports$deleted &lt;- NULL\n\n\n# some reports are obivously duplicates: same x and y and date (time may vary slighly)\ntick_reports |&gt;\n  group_by(x, y, date) |&gt;\n  filter(n() &gt; 1) |&gt;\n  select(id, datetime)\n\n# A tibble: 397 × 5\n# Groups:   x, y, date [176]\n        x      y date          id datetime           \n    &lt;int&gt;  &lt;int&gt; &lt;date&gt;     &lt;int&gt; &lt;dttm&gt;             \n 1 609729 261433 2015-04-13   118 2015-04-13 08:34:29\n 2 609729 261433 2015-04-13   119 2015-04-13 08:34:29\n 3 731962 253501 2015-08-26  2028 2015-08-26 20:46:02\n 4 731962 253501 2015-08-26  2029 2015-08-26 20:46:02\n 5 621424 264799 2016-07-18  5737 2016-07-18 13:52:11\n 6 621424 264799 2016-07-18  5738 2016-07-18 13:53:07\n 7 634791 249092 2016-07-25  5967 2016-07-25 08:18:49\n 8 634791 249092 2016-07-25  5968 2016-07-25 08:18:49\n 9 634791 249092 2016-07-25  5969 2016-07-25 08:18:49\n10 667235 212674 2016-08-04  6233 2016-08-04 09:34:30\n# ℹ 387 more rows\n\n# keep only distinct reports\ntick_reports &lt;- tick_reports |&gt;\n  distinct(x, y, date, .keep_all = TRUE)\n\n\ntick_reports$x &lt;- NULL\ntick_reports$y &lt;- NULL\n\ntick_reports_sf &lt;- st_as_sf(tick_reports, coords = c(\"lon\", \"lat\"), crs = 4326) |&gt;\n  st_transform(2056)\n\n\ntick_reports_sf &lt;- cbind(tick_reports_sf, st_coordinates(tick_reports_sf))\n\ntick_reports_sf &lt;- tick_reports_sf[switzerland, , ]\n\n\ntick_reports_sf$year &lt;- year(tick_reports_sf$date)\n\nggplot(tick_reports_sf) +\n  geom_sf() +\n  facet_wrap(~year)\n\n\n\ntick_reports_sf$year &lt;- NULL\n\nticks_path &lt;- \"data-processed/Ticks\"\n\nif(!dir.exists(ticks_path)) {dir.create(ticks_path)}\n\nst_write(tick_reports_sf, file.path(ticks_path, \"tick_reports.gpkg\"), \"reports_0.2\")\n\nWriting layer `reports_0.2' to data source \n  `data-processed/Ticks/tick_reports.gpkg' using driver `GPKG'\nWriting 39236 features with 6 fields and geometry type Point."
  },
  {
    "objectID": "02_Prepare_covariates.html#mask",
    "href": "02_Prepare_covariates.html#mask",
    "title": "2  Prepare covariates",
    "section": "2.1 Mask",
    "text": "2.1 Mask\n\nswisstlm_temp_path &lt;- \"data-temp/swissTLM/\"\nunzip(\"data-raw/public/swissTLM/swisstlmregio_2022_2056.gdb.zip\", exdir = swisstlm_temp_path)\n\nswitzerland &lt;- read_sf(\"data-raw/public/swissTLM/swissBOUNDARIES3D_1_4_LV95_LN02.gdb\", \"TLM_LANDESGEBIET\") |&gt;\n  st_zm() |&gt;\n  filter(NAME != \"Liechtenstein\") |&gt;\n  st_union() |&gt;\n  st_transform(2056)\n\ntlm_region_lake &lt;- read_sf(file.path(swisstlm_temp_path, \"swissTLMRegio_Produkt_LV95.gdb\"), \"TLMRegio_Lake\")\n\ntlm_region_lake &lt;- tlm_region_lake[switzerland,,]\n\ntlm_region_lake &lt;- tlm_region_lake |&gt;\n    slice_max(SHAPE_Area, n = 10)\n\nmask_template &lt;- rast(crs = \"epsg:2056\", resolution = 100, xmin = 2485000, xmax = 2834000, ymin = 1075000, ymax = 1296000)\n\nswitzerland_mask &lt;- terra::rasterize(vect(switzerland), mask_template)\n\nswitzerland_mask &lt;- mask(switzerland_mask, tlm_region_lake,inverse = TRUE) \n\nmask_path &lt;- \"data-processed/Mask/\"\nif(!dir.exists(mask_path)) dir.create(mask_path, recursive = TRUE)\nwriteRaster(switzerland_mask, file.path(mask_path, \"Mask.tif\"), datatype = \"INT1U\", overwrite = TRUE)"
  },
  {
    "objectID": "02_Prepare_covariates.html#population",
    "href": "02_Prepare_covariates.html#population",
    "title": "2  Prepare covariates",
    "section": "2.2 Population",
    "text": "2.2 Population\n\nzips &lt;- list.files(\"data-raw/public/Population/\", full.names = TRUE)\n\nzip_csvs &lt;- sapply(zips, \\(x){\n    df &lt;- unzip(x, list = TRUE)\n\n    df$Name[str_detect(df$Name, \"STATPOP\\\\d{4}.csv\")]\n})\n\n# names(zip_csvs)\n\npopulation_path &lt;- \"data-temp/Population\"\n\nif(!dir.exists(population_path)) dir.create(population_path)\n\n\nimap(zip_csvs, \\(csv_i, zip_i){\n    unzip(zip_i, csv_i, exdir = population_path, junkpaths = TRUE)\n}) |&gt;\n    invisible()\n\n\npop_csvs &lt;- list.files(population_path, \"STATPOP\", full.names = TRUE)\n\npop_csvs &lt;- pop_csvs[as.integer(str_match(basename(pop_csvs), \"\\\\d{4}\"))&gt;=2015]\n\npopulation &lt;- map(pop_csvs, \\(x){\n        read_delim(x, col_select = c(E_KOORD, N_KOORD, matches(\"B\\\\d{2}BTOT\"))) |&gt;\n            rast()\n    }) |&gt;\n    rast()\n\n# add crs information\ncrs(population) &lt;- \"epsg:2056\"\n\ndates &lt;- paste0(\"20\",str_match(names(population), \"B(\\\\d{2})BTOT\")[,2],\"-01-01\") |&gt;\n  as.Date()\n\ntime(population) &lt;- dates\n\nnames(population) &lt;- dates\n\npopulation_path2 &lt;- \"data-processed/Population\"\nif(!dir.exists(population_path)) dir.create(population_path2)\nwriteRaster(population, file.path(population_path2, \"Population_2015-2021.tif\"))\n\nError: [writeRaster] file exists. You can use 'overwrite=TRUE' to overwrite it"
  },
  {
    "objectID": "02_Prepare_covariates.html#elevation",
    "href": "02_Prepare_covariates.html#elevation",
    "title": "2  Prepare covariates",
    "section": "2.3 Elevation",
    "text": "2.3 Elevation\n\ndataset: ./data/prepared/DHM/DHM25.tif (CRS: EPSG: 21781)\n\nTemperature has a big impact on the occurance of ticks. The mentioned expert based model used elevation as a proxy for temperature and removed risk classes based according to the following system:\n\n\n\nElevation\nClassification\n\n\n\n\n1200 - 1600\nminus 1 class\n\n\n1600 - 1900\nminus 2 classes\n\n\n&gt; 1900\n0\n\n\n\nThe Digital height model DHM25 is a dataset with 25 m resolution describing elevation.\n\n\ndata preperation\ndhm_path &lt;- \"data-temp/DHM/\"\nif(!dir.exists(dhm_path)) dir.create(dhm_path)\nunzip(\"data-raw/public/DHM/DHM25_MM_ASCII_GRID.zip\", exdir = dhm_path)\n\ndhm25 &lt;- rast(file.path(dhm_path, \"ASCII_GRID_1part/dhm25_grid_raster.asc\"))\n\n# set CRS information\ncrs(dhm25) &lt;- \"epsg: 21781\"\n\n\n\n# this takes a lot of time! I will provide the reprojected data as a download\ndhm25_2056 &lt;- project(dhm25, \"epsg: 2056\")\n\ndhm_path2 &lt;- \"data-processed/DHM\"\nif(!dir.exists(dhm_path2)) dir.create(dhm_path2)\nwriteRaster(dhm25_2056, file.path(dhm_path2, \"DHM25_2056.tif\"))"
  },
  {
    "objectID": "02_Prepare_covariates.html#weather",
    "href": "02_Prepare_covariates.html#weather",
    "title": "2  Prepare covariates",
    "section": "2.4 Weather",
    "text": "2.4 Weather\n\nDataset: prepared/Weather\nVariables:\n\nRhiresM: Monthly precipitation\nSrelM: Monthly relative sunshine duration\nTabsM: Monthly mean temperature\n\n\nThese variables (or a combination of them) raised or lowered the risk class according to the following system:\nWe have prepared some weather data from the Federal Office of Meteorology and Climatology MeteoSwiss (Meteo Schweiz). We will provide you with the following datasets (years 2015 - 2021):\nA full list of the available variables can be found here.\nThis is how we prepared the data:\n\nfiles_monthly &lt;- c(\"RhiresM_61_21_ch01r.swiss.lv95.zip\", \"SrelM_71_21_ch01r.swiss.lv95.zip\", \"TabsM_61_21_ch01r.swiss.lv95.zip\")\n\nweather_path &lt;- \"data-temp/Weather\"\nif(!dir.exists(weather_path)) dir.create(weather_path)\n\nunzip(\"data-raw/public/Wetter/Klimadaten_Feb22.zip\", files = file.path(\"Klimadaten_Feb22\", files_monthly), exdir = weather_path, junkpaths = TRUE)\n\nweather_zips &lt;- list.files(weather_path, pattern = \"\\\\.zip$\", full.names = TRUE)\n\n\nsapply(weather_zips, \\(x){\n    nc_names &lt;- unzip(x, list = TRUE)$Name\n    nc_select &lt;- nc_names[as.integer(str_match(nc_names, \"(\\\\d{4})\\\\d{8}\")[,2]) &gt;= 2015]\n    nc_select &lt;- nc_select[!is.na(nc_select)]\n    exdir &lt;- file.path(weather_path, str_match(basename(x), \"([a-zA-Z]+)\")[,2])\n    unzip(x, files = nc_select, exdir = exdir, junkpaths = TRUE)\n})\n\n\nfile.remove(weather_zips)\n \n\n\nweather_files &lt;- list.files(weather_path, \"\\\\.nc\", recursive = TRUE, full.names = TRUE)\n\n\nweather_path2 &lt;- \"data-processed/Weather\"\nmap(weather_files, \\(file_i){\n  rast_i &lt;- rast(file_i)\n\n  from_to &lt;- str_match(file_i, \"(\\\\d{8})\\\\d{4}_(\\\\d{8})\\\\d{4}\")[,2:3] |&gt;\n    as.Date(format = \"%Y%m%d\")\n\n  measurement &lt;- str_match(basename(file_i), \"^[a-zA-Z]+\")[,1]\n\n  new_filepath &lt;- file.path(weather_path2,measurement)\n  if(!dir.exists(new_filepath)) dir.create(new_filepath,recursive = TRUE)\n  new_filename &lt;- paste0(paste(from_to, collapse = \"_\"), \".tif\")\n\n\n\n  times &lt;- seq(from_to[1], from_to[2], by = \"month\")\n  time(rast_i) &lt;- times\n  crs(rast_i) &lt;- \"epsg:2056\"\n  writeRaster(rast_i, file.path(new_filepath, new_filename), overwrite = TRUE)\n})\n\nTo import the dataset:\n\nweather_files2 &lt;- list.files(weather_path2, \"\\\\.tif$\", recursive = TRUE, full.names = TRUE)\n\n\nrhires_2015 &lt;- rast(weather_files2[1])\n\nplot(rhires_2015)\n\n\n\n# to get the mean over all months\n\nmean(rhires_2015) |&gt;\n  plot()"
  },
  {
    "objectID": "02_Prepare_covariates.html#forest-mix",
    "href": "02_Prepare_covariates.html#forest-mix",
    "title": "2  Prepare covariates",
    "section": "2.5 Forest mix",
    "text": "2.5 Forest mix\nPercentage of “Laubbaumholz” (deciduous trees) in a 10m grid. The dataset is provided by the Federal Office for the Environment.\nThis dataset is also the basis of the dataset Forest Type which discriminates forest type into two classes based on the percentage of deciduous trees.\n\nforest_mix_path &lt;- \"data-raw/public/Forest/Waldmischungsgrad_2018_10m_2056.tif\"\nforest_mix &lt;- rast(forest_mix_path)\n\nplot(forest_mix)\n\n\n\nforest_mix_path2 &lt;- \"data-processed/Forest\"\nif(!dir.exists(forest_mix_path2)) dir.create(forest_mix_path2)\nfile.copy(forest_mix_path, file.path(forest_mix_path2, basename(forest_mix_path)), overwrite = TRUE)\n\n[1] TRUE\n\nbasename(forest_mix_path)\n\n[1] \"Waldmischungsgrad_2018_10m_2056.tif\""
  },
  {
    "objectID": "02_Prepare_covariates.html#vegetation-height",
    "href": "02_Prepare_covariates.html#vegetation-height",
    "title": "2  Prepare covariates",
    "section": "2.6 Vegetation Height",
    "text": "2.6 Vegetation Height\nlocation: ftp://ftp.wsl.ch/pub/ginzler/VHM_LFI (user: anonymous)"
  }
]